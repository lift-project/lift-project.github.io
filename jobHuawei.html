---
title: Research Associate Position at Edinburgh University
subtitle: Efficient Neural Network Code Generation on Mobile GPUs

layout: job_advert
---
<div id="main">
    <div class="container">
        <div class="row">

            <!-- Content -->
            <div id="content" class="12u skel-cell-important">

The School of Informatics, University of Edinburgh, invites applications for a post-doctoral research position on the theme: Efficient Neural Network Code Generation on Mobile GPUs.
The position is funded by Huawei Innovation Research Program FLAGSHIP (HIRP FLAGSHIP) project for a duration of up to two years with possible extension.            
            
                <section>
                    <header>
                        <span class="byline">Project Description</span>
                    </header>
                    <p>Neural network applications are used extensively in areas such as computer vision, machine translation and business analytic.
                    This has become possible thanks to the development of powerful parallel hardware.
                    However, writing efficient parallel implementation for these algorithms remains a challenge even for expert programmers, especially on power constraints devices such as mobile GPUs.
                    Programmers have to fine-tune their code for the special characteristics of the targeted hardware.
                    This expensive and time-consuming process has to be repeated every time new hardware emerge or when the neural network architecture is updated.</p>
                    
                    <p>In this project, we propose to build upon the existing <span class="lift-bold">Lift</span> compiler and extend this work to the generation and tuning of neural networks for mobile GPUs.
                    <span class="lift-bold">Lift</span> is a novel approach developed at Edinburgh to achieving performance portability on parallel accelerators.
                    <span class="lift-bold">Lift</span> combines a high-level functional data parallel language with a system of rewrite rules which encode algorithmic and hardware-specific optimisation choices.
                    Applications written in <span class="lift-bold">Lift</span> are able to take advantage of GPUs, transparently from the user.</p>
                    
                    <p>This project will augment <span class="lift-bold">Lift</span> with the ability to express and optimise machine-learning algorithms and exploit effectively mobile GPUs.
                    The main idea is to express neural network computation as <span class="lift-bold">Lift</span> programs, which are then automatically compiled and optimised for the GPU.
                    In this project, we will explore mobile-GPU specific optimisations, neural network optimisations and the use of performance model to make prediction about the performance potential of the GPU for various neural networks.</p>
                </section>
                
                <section>
                    <header>
                        <span class="byline">Project Description</span>
                    </header>
                    
                    <p>Your main task will consist of supporting the research activities in the Lift research group and achieve the project's objectives established jointly with Huawei, our industrial partner.
                    The position will be a mix of research and development with the opportunity to take an active role in the co-supervision of the PhD students in the <span class="lift-bold">Lift</span> group.
                    The main success criteria will be the publications of high quality scientific papers and the delivery of a working prototype compiler targeted at neural networks.</p>

						  <p>On a more technical note, the <span class="lift-bold">Lift</span> language is deeply functional in nature and the Lift compiler is mostly written in Scala.
						  Therefore, the ideal candidate is expected to have a strong background in functional programming.
						  Since our code generator targets OpenCL and we plan to integrate it with the Caffe C++ library, we also expect the ideal candidate to have a good knowledge of C/C++ programming and some familiarities with OpenCL or CUDA.
						  Knowledge about neural networks algorithms is desirable although not strictly necessary as this can be learnt during the course of the project.</p>
						                    
                </section>               
                
                <section>
                    <header>
                        <span class="byline">Career Development Opportunities</span>
                    </header>
                    <p>We are looking for the brightest minds to pursue cutting-edge research with a direct industry application.
                    You will be part of a world-leading research group in the area of compilers and will be given the ability to interact directly with industry and to network with other scientists through conferences and other events.
                    The successful candidate will be offered guidance and mentoring to seek an academic or industrial research position in a top institution at the end of the project.</p>
                </section>                           
                
                </div>

                
                <div class="row">
                    <header>
                        <span class="byline">Job Description</span>
                    </header>
                    <div class="12u">
                        <ul>
                            <li>Parallel mappings space exploration</li>
                            <li>Memory tiling</li>
                            <li>Memory coalescing</li>
                            <li>Approximate computations</li>
                            <li>Float quantization</li>
                            <li>Neuron pruning</li>
                            <li>Training batch size autotuning</li>
                        </ul>
                    </div>                    
                </div>
            </div>

            <!-- Sidebar -->
            <div id="sidebar" class="4u">
                <section class="profile">
                    <header>
                        <h2>Researcher</h2>
                    </header>
                    <div class="6u">
                        <a href="https://naumsmogers.me/" class="image full">
                            <img src="images/naums.jpg" alt=""></a>                        
                        <a href="https://naumsmogers.me/">Naums Mogers</a>
                        <br>
                        PhD Student
                        <br>
                        <a href="http://www.ed.ac.uk/informatics/">University of Edinburgh</a>
                    </div>
                </section>
                <section>
                    <header>
                        <h2>Talks</h2>
                    </header>
                    <div class="row">
                        <section>
                            <ul class="style">
                                <li>
                                    <p class="posted">June 14, 2017 @ the PPar Student Showcase Event</p>
                                    <p><a href="presentations/2017/MogersPPar2017.pdf">
                                        Optimization of neural computations using a functional data-parallel language</a></p>
                                </li>
                            </ul>
                        </section>
                    </div>
                </section>
                <section>
                    <header>
                        <h2>Posters</h2>
                    </header>
                    <ul class="style">
                        <li>
                            <p class="posted">June 14, 2017 @ the PPar Student Showcase Event</p>
                            <p><a href="posters/2017/MogersPPar2017Poster.png">
                                Optimization of neural computations using a functional data-parallel language</a></p>
                        </li>
                            <li>
                                <p class="posted">November 10, 2016 @ the PPar IEE</p>
                                <p><a href="posters/2016/MogersPParIEE2016Poster.pdf">
                                    Optimization of neural computations using a functional data-parallel language</a></p>
                            </li>
                    </ul>
                </section>
            </div>

        </div>
    </div>
</div>
