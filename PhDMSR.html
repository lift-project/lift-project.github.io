---
title: High-Level Synthesis of Neural Networks for FPGAs with LIFT

layout: job_advert
---
<div id="main">
  <div class="container">
    <div class="row">
      
      <!-- Content -->
      <div id="content" class="12u skel-cell-important">
	
	<section>
	  <header>
            <span class="byline">High-Level Synthesis of Neural Networks for FPGAs with LIFT</span>
	  </header>
	  
	  <p>
	    We invite applications for a <b>PhD</b> position on the theme: <b>High-Level Synthesis of Neural Networks for FPGAs with LIFT</b>.	  
	    This position is fully funded (for EU nationals, although exceptional overseas candidates might be considered) by a scholarship from Microsoft Research for <b>3.5 years</b> which is the typical length of PhD studies.	    
	    The starting date is flexible.
	  </p>
          
	  
        </section>            
        
        <section>
          <header>
            <span class="byline">Project Description</span>
          </header>
	  
	  <p>
	    Machine-learning applications are becoming pervasive throughout our entire society.
	    They are already used extensively in areas such as machine translation and business data analytic and are set to revolutionise our world with applications such as self-driving cars.
	    This has become possible thanks to the massive amount of data available for training coupled with the development of powerful parallel hardware.
	  </p>

	  <p>
	    However, writing efficient parallel implementation for these algorithms remains a challenge for the non-experts.
	    The presence of parallel accelerators such as GPUs (Graphic Processing Units) or FPGAs (Field-Programmable Gate Arrays) means that software has to be specifically written for these devices.
	    Programmers have to use different programming models and often need to fine-tune their code for the special characteristics of the targeted hardware.
	    This expensive and time-consuming process needs to be repeated every time new hardware emerge or even when the software stack is updated.	  
	    To enable machine-learning expert to unlock the potential of future systems, we need to focus on new software programming model that abstract away most of the hardware details.
	  </p>

	  <p>
	    In this project, we propose to build upon our existing <span class="lift-bold">Lift</span> project, an Open Source language and compiler initially developed at Edinburgh University.
	    <span class="lift-bold">Lift</span> combines a high-level functional data parallel language with a system of rewrite rules which encodes algorithmic and hardware-specific optimisation choices.
	    An applications written in <span class="lift-bold">Lift</span> is able to take advantage of parallel accelerators available in the systems, transparently from the user.
	    This proposal is about augmenting <span class="lift-bold">Lift</span> with the ability to express and optimise machine-learning algorithms and exploit effectively FPGA hardware.
	  </p>
		    
        </section>
        
        	
	<section>
	  <header>
	    <span class="byline">Technical requirements</span>
	  </header>
	  <div class="12u">
	    <ul>
	      <li>Hardware design experience (in VHDL or Verilog)</li>
	      <li>Good functional programming and object-oriented programming skills</li>
	      <li>Compiler knowledge</li>
	      <li>Basic understanding of machine-learning algorithms desirable</li>	      
	    </ul>
	  </div>                    
	</section>                           
	
	
	<section>
	  <header>
	    <span class="byline">How to apply</span>
	  </header>
	  <div class="12u">	    
	    <p>
	      Please send a CV, transcripts (courses taken + marks achieved) and a short introduction highlighting the experience you have with respect to the above requirements to: <a href="mailto:christophe.dubach@ed.ac.uk">christophe.dubach@ed.ac.uk</a>
	    </p>                        
	  </div>
	</section>                           
	
      </div>
      
    </div>                
    
  </div>
</div>

